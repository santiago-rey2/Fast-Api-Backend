# Scripts de Base de Datos

# Scripts - Examples

Esta carpeta contiene scripts de ejemplo para demostrar las capacidades del sistema.

## ğŸ“ Archivos Disponibles

### ğŸ•·ï¸ `restaurant_scraper.py`
**Sistema completo de web scraping para cartas de restaurantes**

Extrae automÃ¡ticamente informaciÃ³n de menÃºs desde URLs de restaurantes y los carga en el sistema.

**CaracterÃ­sticas:**
- DetecciÃ³n inteligente de precios (â‚¬, EUR, euros)
- ClasificaciÃ³n automÃ¡tica por categorÃ­as
- Mapeo de alÃ©rgenos comunes
- Soporte para plataformas especializadas (WordPress, Wix, Squarespace)
- Carga directa a base de datos
- ExportaciÃ³n a JSON

**Ejemplo de uso:**
```python
from restaurant_scraper import RestaurantScraper

scraper = RestaurantScraper()
data = scraper.scrape_restaurant("https://restaurante-ejemplo.com/carta")

if data['total_items'] > 0:
    scraper.load_to_database(data)
    print(f"âœ… {data['total_items']} elementos cargados")
```

### ğŸ§ª `test_scraper.py`
**Herramienta de testing para el scraper**

Proporciona una interfaz para probar el scraper de manera interactiva o automÃ¡tica.

**Funcionalidades:**
- Prueba interactiva con URL personalizada
- Tests automÃ¡ticos con URLs de ejemplo
- Vista previa de datos antes de cargar en BD
- ExportaciÃ³n automÃ¡tica a JSON

**Uso:**
```bash
cd scripts-examples
python test_scraper.py
```

### ğŸ¯ `specialized_extractors.py`
**Extractores especializados para diferentes plataformas web**

Contiene mÃ©todos especÃ­ficos para extraer datos de plataformas populares como WordPress, Wix, Squarespace, etc.

**Extractores disponibles:**
- WordPress (clases especÃ­ficas de menÃºs)
- Wix (estructura de componentes)
- Squarespace (layout de productos)
- Tablas HTML genÃ©ricas
- JSON-LD estructurado

## ğŸš€ Instrucciones de Uso

### 1. InstalaciÃ³n de Dependencias
```bash
pip install beautifulsoup4 requests lxml
```

### 2. ConfiguraciÃ³n de Base de Datos
AsegÃºrate de que la base de datos estÃ© configurada:
```bash
cd scripts
python setup_complete_database.py
```

### 3. Prueba del Scraper
```bash
cd scripts-examples
python test_scraper.py
```

### 4. Uso ProgramÃ¡tico
```python
# Importar el scraper
from restaurant_scraper import RestaurantScraper

# Crear instancia
scraper = RestaurantScraper()

# Scrappear restaurante
data = scraper.scrape_restaurant("https://ejemplo.com/menu")

# Cargar en base de datos
success = scraper.load_to_database(data)

# O guardar como JSON
filepath = scraper.save_to_json(data)
```

## ğŸ“Š Formato de Datos ExtraÃ­dos

El scraper devuelve datos en el siguiente formato:

```json
{
    "restaurante_info": {
        "url": "https://ejemplo.com",
        "titulo": "Restaurante Ejemplo"
    },
    "total_items": 25,
    "items": [
        {
            "nombre": "Paella Valenciana",
            "descripcion": "Arroz tradicional con mariscos",
            "precio": 18.50,
            "categoria": "Principales",
            "alergenos": ["gluten", "mariscos"]
        }
    ],
    "categorias": {
        "Entrantes": [...],
        "Principales": [...],
        "Postres": [...]
    },
    "extraction_date": "2024-01-15T10:30:00"
}
```

## ğŸ¯ Casos de Uso

### Cargar MenÃº Completo
```python
scraper = RestaurantScraper()
data = scraper.scrape_restaurant("https://restaurante.com/carta")
scraper.load_to_database(data)
```

### Solo Obtener Datos (sin cargar)
```python
scraper = RestaurantScraper()
data = scraper.scrape_restaurant("https://restaurante.com/carta")
scraper.save_to_json(data, "menu_backup.json")
```

### Procesar MÃºltiples Restaurantes
```python
urls = [
    "https://restaurante1.com/menu",
    "https://restaurante2.com/carta",
    "https://restaurante3.com/platos"
]

scraper = RestaurantScraper()
for url in urls:
    try:
        data = scraper.scrape_restaurant(url)
        scraper.load_to_database(data)
        print(f"âœ… {url} procesado")
    except Exception as e:
        print(f"âŒ Error en {url}: {e}")
```

## ğŸ”§ PersonalizaciÃ³n

### AÃ±adir Nuevos Patrones de Precios
Edita `restaurant_scraper.py` y aÃ±ade patrones al mÃ©todo `extract_price()`:

```python
price_patterns = [
    r'(\d+[.,]\d{2})\s*â‚¬',
    r'(\d+[.,]\d{2})\s*EUR',
    r'(\d+[.,]\d{2})\s*euros',
    # AÃ±adir nuevo patrÃ³n aquÃ­
    r'Precio:\s*(\d+[.,]\d{2})'
]
```

### AÃ±adir Nuevas CategorÃ­as
Modifica el diccionario `categoria_keywords` en `detect_categoria()`:

```python
categoria_keywords = {
    'Entrantes': ['entrada', 'aperitivo', 'tapa'],
    'Principales': ['principal', 'segundo', 'plato fuerte'],
    'Postres': ['postre', 'dulce', 'helado'],
    # Nueva categorÃ­a
    'Bebidas': ['bebida', 'refresco', 'agua', 'vino']
}
```

## ğŸ“ Notas Importantes

- **Respeto por robots.txt**: El scraper respeta las polÃ­ticas de scraping
- **Rate Limiting**: Incluye delays entre solicitudes para no sobrecargar servidores
- **Error Handling**: Manejo robusto de errores con fallbacks
- **Logging**: Registro detallado de operaciones para debugging

## ğŸ› Troubleshooting

### Error de ConexiÃ³n
```
Error: Timeout o conexiÃ³n rechazada
```
**SoluciÃ³n**: Verificar conectividad y que la URL sea accesible

### No se Encuentran Elementos
```
Warning: 0 elementos encontrados
```
**SoluciÃ³n**: La pÃ¡gina puede usar JavaScript dinÃ¡mico o tener una estructura no estÃ¡ndar

### Error de Base de Datos
```
Error: No se pudo cargar en BD
```
**SoluciÃ³n**: Verificar configuraciÃ³n de BD en `src/core/database.py`

## ğŸ“‹ Scripts Disponibles

### 1. ğŸ—‘ï¸ `clear_database.py`
**PropÃ³sito**: Elimina todas las tablas de la base de datos dejÃ¡ndola completamente vacÃ­a.

**Uso**:
```bash
python scripts-examples/clear_database.py
```

**CaracterÃ­sticas**:
- âœ… Elimina TODAS las tablas de la base de datos
- âœ… Maneja foreign key constraints de MySQL
- âœ… Verifica que la base de datos quede completamente vacÃ­a
- âš ï¸ NO carga ningÃºn dato - solo eliminaciÃ³n

---

### 2. ğŸ“¦ `load_sample_data.py`
**PropÃ³sito**: Carga datos de ejemplo en la base de datos (platos y vinos realistas).

**Uso**:
```bash
python scripts-examples/load_sample_data.py
```

**Prerrequisitos**:
- La base de datos debe tener la estructura bÃ¡sica (categorÃ­as, alÃ©rgenos, etc.)
- Se recomienda ejecutar primero `setup_complete_database.py`

**Datos que carga**:
- ğŸ½ï¸ Platos de ejemplo con descripciones realistas
- ğŸ· Vinos de ejemplo con bodegas y enÃ³logos
- ğŸ­ Bodegas espaÃ±olas
- ğŸ‘¨â€ğŸ³ EnÃ³logos reconocidos

---

### 3. ğŸš€ `setup_complete_database.py`
**PropÃ³sito**: Script completo que hace todo - elimina, crea estructura y carga datos.

**Uso**:
```bash
python scripts-examples/setup_complete_database.py
```

**Lo que hace**:
1. ğŸ”¥ Elimina todas las tablas existentes
2. ğŸ—ï¸ Recrea la estructura de la base de datos
3. ğŸŒ± Carga datos por defecto (categorÃ­as, alÃ©rgenos, etc.)
4. ğŸ‘¤ Crea usuario administrador (admin/admin123)
5. ğŸ“¦ Carga datos de ejemplo (platos y vinos)

**Â¡Recomendado para setup inicial!**

---

## ğŸ”„ Flujos de Trabajo Comunes

### Setup inicial completo
```bash
python scripts-examples/setup_complete_database.py
```

### Limpiar y empezar de cero (sin datos de ejemplo)
```bash
python scripts-examples/clear_database.py
# Luego usar la API o cargar datos manualmente
```

### Solo cargar datos de ejemplo
```bash
python scripts-examples/load_sample_data.py
```

---

## ğŸ“ Archivos CSV de Ejemplo

- `example_alergenos.csv` - Lista de alÃ©rgenos segÃºn legislaciÃ³n espaÃ±ola
- `example_bodegas.csv` - Bodegas espaÃ±olas de referencia  
- `example_categorias.csv` - CategorÃ­as de platos y vinos

## ğŸ” Usuario Administrador

Los scripts que crean estructura tambiÃ©n crean un usuario administrador:
- **Username**: admin
- **Password**: admin123
- **Role**: admin

Este usuario puede acceder a todos los endpoints protegidos de la API.
